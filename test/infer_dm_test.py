#!/usr/bin/env python
"""
æµ‹è¯•æ¨¡å‹é‡è½½è€—æ—¶ - æ¨¡æ‹ŸçœŸå®åœºæ™¯ï¼š
1. æœºæ¢°è‡‚/ç›¸æœºè¿æ¥å¹¶ä¿æŒ
2. æ¨¡å‹æ¨ç†è¿è¡Œä¸€æ®µæ—¶é—´
3. å¸è½½æ¨¡å‹
4. é‡æ–°åŠ è½½æ¨¡å‹
5. ç»§ç»­æ¨ç†
"""

import argparse
import time
import gc
from pathlib import Path

import numpy as np
import torch

from lerobot.policies.act.modeling_act import ACTPolicy
from lerobot.cameras.opencv import OpenCVCameraConfig
from lerobot_robot_multi_robots.dm_arm import DMFollower
from lerobot_robot_multi_robots.config_dm_arm import DMFollowerConfig

# ç›¸æœºé…ç½®
CAMERAS_CONFIG = {
    "end": OpenCVCameraConfig(
        index_or_path="/dev/com-1.2-video",
        width=640,
        height=480,
        fps=30,
    ),
    "eye": OpenCVCameraConfig(
        index_or_path=2,
        width=1280,
        height=720,
        fps=30,
    ),
}

DEFAULT_MODEL_PATH = "./outputs/leaf_v0_model/checkpoints/last/pretrained_model"


def preprocess_observation(obs_dict: dict, device: torch.device) -> dict:
    """é¢„å¤„ç†è§‚æµ‹"""
    processed = {}
    state_keys = [
        "joint_1.pos", "joint_2.pos", "joint_3.pos",
        "joint_4.pos", "joint_5.pos", "joint_6.pos", "gripper.pos",
    ]
    state = np.array([obs_dict[key] for key in state_keys], dtype=np.float32)
    processed["observation.state"] = torch.from_numpy(state).unsqueeze(0).to(device)
    
    for cam_name in ["eye", "end"]:
        if cam_name in obs_dict:
            img = obs_dict[cam_name]
            img = np.transpose(img, (2, 0, 1)).astype(np.float32) / 255.0
            processed[f"observation.images.{cam_name}"] = (
                torch.from_numpy(img).unsqueeze(0).to(device)
            )
    return processed


def postprocess_action(action: torch.Tensor) -> dict:
    """åå¤„ç†åŠ¨ä½œ"""
    action_np = action.squeeze(0).cpu().numpy()
    return {
        "joint_1.pos": float(action_np[0]),
        "joint_2.pos": float(action_np[1]),
        "joint_3.pos": float(action_np[2]),
        "joint_4.pos": float(action_np[3]),
        "joint_5.pos": float(action_np[4]),
        "joint_6.pos": float(action_np[5]),
        "gripper.pos": float(action_np[6]),
    }


def run_inference(policy, robot, device, duration_sec: float, freq: float = 30.0):
    """è¿è¡Œæ¨ç†ä¸€æ®µæ—¶é—´"""
    print(f"   å¼€å§‹æ¨ç† {duration_sec}s (é¢‘ç‡ {freq} Hz)...")
    period = 1.0 / freq
    start_time = time.perf_counter()
    steps = 0
    
    while time.perf_counter() - start_time < duration_sec:
        loop_start = time.perf_counter()
        
        raw_obs = robot.get_observation()
        obs = preprocess_observation(raw_obs, device)
        
        with torch.inference_mode():
            action = policy.select_action(obs)
        
        action_dict = postprocess_action(action)
        robot.send_action(action_dict)
        
        steps += 1
        
        # æ§åˆ¶é¢‘ç‡
        elapsed = time.perf_counter() - loop_start
        if elapsed < period:
            time.sleep(period - elapsed)
    
    actual_time = time.perf_counter() - start_time
    actual_freq = steps / actual_time
    print(f"   âœ“ æ¨ç†å®Œæˆ: {steps} æ­¥, å®é™…é¢‘ç‡ {actual_freq:.1f} Hz")


def load_model(model_path: str, device: torch.device):
    """åŠ è½½æ¨¡å‹"""
    t0 = time.perf_counter()
    
    load_start = time.perf_counter()
    policy = ACTPolicy.from_pretrained(model_path)
    load_time = time.perf_counter() - load_start
    
    to_start = time.perf_counter()
    policy.to(device)
    to_time = time.perf_counter() - to_start
    
    policy.eval()
    
    total_time = time.perf_counter() - t0
    
    return policy, {
        "from_pretrained": load_time,
        "to_device": to_time,
        "total": total_time,
    }


def unload_model(policy):
    """å¸è½½æ¨¡å‹"""
    t0 = time.perf_counter()
    
    policy.cpu()
    del policy
    gc.collect()
    
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
    unload_time = time.perf_counter() - t0
    return unload_time


def main():
    parser = argparse.ArgumentParser(description="æµ‹è¯•æ¨¡å‹é‡è½½è€—æ—¶ï¼ˆçœŸå®åœºæ™¯ï¼‰")
    parser.add_argument(
        "--model_path", type=str, default=DEFAULT_MODEL_PATH, help="æ¨¡å‹è·¯å¾„"
    )
    parser.add_argument(
        "--port", type=str, default="/dev/ttyACM0", help="æœºæ¢°è‡‚ä¸²å£"
    )
    parser.add_argument(
        "--device", type=str, default="cuda", help="æ¨ç†è®¾å¤‡"
    )
    parser.add_argument(
        "--iterations", type=int, default=3, help="é‡è½½æµ‹è¯•æ¬¡æ•°"
    )
    parser.add_argument(
        "--run_duration", type=float, default=5.0, help="æ¯æ¬¡æ¨ç†è¿è¡Œæ—¶é•¿ï¼ˆç§’ï¼‰"
    )
    parser.add_argument(
        "--freq", type=float, default=30.0, help="æ¨ç†é¢‘ç‡ Hz"
    )
    args = parser.parse_args()

    device = torch.device(args.device if torch.cuda.is_available() else "cpu")
    
    print("=" * 70)
    print("æ¨¡å‹é‡è½½å»¶è¿Ÿæµ‹è¯• - çœŸå®åœºæ™¯æ¨¡æ‹Ÿ")
    print("=" * 70)
    print(f"è®¾å¤‡: {device}")
    print(f"æ¨¡å‹: {args.model_path}")
    print(f"æµ‹è¯•æ¬¡æ•°: {args.iterations}")
    print(f"æ¯è½®æ¨ç†æ—¶é•¿: {args.run_duration}s @ {args.freq}Hz")
    print("=" * 70)

    # ===================== 1. åˆå§‹åŒ–ç¡¬ä»¶ï¼ˆä¸€æ¬¡æ€§ï¼Œä¿æŒè¿æ¥ï¼‰=====================
    print("\n[æ­¥éª¤ 1] åˆå§‹åŒ–æœºæ¢°è‡‚å’Œç›¸æœº...")
    init_start = time.perf_counter()
    
    robot_config = DMFollowerConfig(
        port=args.port,
        cameras=CAMERAS_CONFIG,
        joint_velocity_scaling=0.1,
        disable_torque_on_disconnect=True,
    )
    robot = DMFollower(robot_config)
    robot.connect()
    
    init_time = time.perf_counter() - init_start
    print(f"âœ“ ç¡¬ä»¶åˆå§‹åŒ–å®Œæˆ: {init_time:.2f}s")

    # ===================== 2. é‡è½½å¾ªç¯æµ‹è¯• =====================
    results = []
    
    for i in range(args.iterations):
        print(f"\n{'='*70}")
        print(f"ç¬¬ {i+1}/{args.iterations} è½®æµ‹è¯•")
        print(f"{'='*70}")
        
        # (1) åŠ è½½æ¨¡å‹
        print(f"\n[A] åŠ è½½æ¨¡å‹...")
        policy, load_stats = load_model(args.model_path, device)
        print(f"    - from_pretrained: {load_stats['from_pretrained']:.3f}s")
        print(f"    - to(device):      {load_stats['to_device']:.3f}s")
        print(f"    - æ€»è®¡:            {load_stats['total']:.3f}s")
        
        # (2) è¿è¡Œæ¨ç†
        print(f"\n[B] è¿è¡Œæ¨ç†...")
        run_inference(policy, robot, device, args.run_duration, args.freq)
        
        # (3) å¸è½½æ¨¡å‹
        print(f"\n[C] å¸è½½æ¨¡å‹...")
        unload_time = unload_model(policy)
        print(f"    - å¸è½½è€—æ—¶: {unload_time:.3f}s")
        
        load_stats["unload"] = unload_time
        results.append(load_stats)
        
        print(f"\n>>> æœ¬è½®é‡è½½å‘¨æœŸ: {load_stats['total'] + unload_time:.3f}s")
        
        # ç­‰å¾…ä¸€ä¸‹
        if i < args.iterations - 1:
            print("\nç­‰å¾… 1 ç§’åå¼€å§‹ä¸‹ä¸€è½®...")
            time.sleep(1.0)
    
    # ===================== 3. ç»Ÿè®¡ç»“æœ =====================
    print(f"\n{'='*70}")
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print(f"{'='*70}")
    
    load_times = [r["total"] for r in results]
    unload_times = [r["unload"] for r in results]
    reload_cycles = [r["total"] + r["unload"] for r in results]
    
    print(f"\nã€æ¨¡å‹åŠ è½½ã€‘")
    print(f"  å¹³å‡:   {np.mean(load_times):.3f}s")
    print(f"  æœ€å¿«:   {np.min(load_times):.3f}s")
    print(f"  æœ€æ…¢:   {np.max(load_times):.3f}s")
    print(f"  æ ‡å‡†å·®: {np.std(load_times):.3f}s")
    
    print(f"\nã€æ¨¡å‹å¸è½½ã€‘")
    print(f"  å¹³å‡:   {np.mean(unload_times):.3f}s")
    print(f"  æœ€å¿«:   {np.min(unload_times):.3f}s")
    print(f"  æœ€æ…¢:   {np.max(unload_times):.3f}s")
    
    print(f"\n{'='*70}")
    print(f"â˜… å®Œæ•´é‡è½½å‘¨æœŸ (å¸è½½ + é‡æ–°åŠ è½½):")
    print(f"    å¹³å‡: {np.mean(reload_cycles):.3f}s")
    print(f"    æœ€å¿«: {np.min(reload_cycles):.3f}s")
    print(f"    æœ€æ…¢: {np.max(reload_cycles):.3f}s")
    print(f"{'='*70}")
    
    print(f"\nğŸ’¡ ROS èŠ‚ç‚¹è®¾è®¡å‚è€ƒ:")
    print(f"   - ç”¨æˆ·è¯·æ±‚æ¨ç†æ—¶ï¼Œé¢„æœŸç­‰å¾…çº¦ {np.mean(reload_cycles):.1f}s")
    print(f"   - å¦‚æœéœ€è¦ä½å»¶è¿Ÿå“åº”ï¼Œå»ºè®®ä¿æŒæ¨¡å‹å¸¸é©»å†…å­˜")
    print(f"{'='*70}")

    # æ–­å¼€è¿æ¥
    print("\næ–­å¼€æœºæ¢°è‡‚è¿æ¥...")
    robot.disconnect()
    print("æµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    main()